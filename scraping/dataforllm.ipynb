{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DFsyhhNCXw78",
    "outputId": "dd2498c2-035a-449c-becc-8ee915c44fc9"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "}\n",
    "\n",
    "def fetch_investopedia_article(url):\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers)\n",
    "        response.raise_for_status()\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching {url}: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "    # Method 1: Find article body div\n",
    "    main_content = soup.find(\"div\", {\"class\": \"article-body\"})\n",
    "\n",
    "    # Method 2: Find all article paragraphs (fallback)\n",
    "    if not main_content:\n",
    "        main_content = soup.find(\"div\", {\"id\": \"mntl-sc-page_1-0\"})\n",
    "\n",
    "    # Method 3: Find all content sections\n",
    "    if not main_content:\n",
    "        sections = soup.find_all(\"div\", class_=\"section-content\")\n",
    "        if sections:\n",
    "            main_content = \"\\n\".join([s.get_text() for s in sections])\n",
    "\n",
    "    if main_content:\n",
    "        if isinstance(main_content, list):\n",
    "            text = \"\\n\".join([elem.get_text(separator=\" \", strip=True) for elem in main_content])\n",
    "        else:\n",
    "            text = main_content.get_text(separator=\" \", strip=True)\n",
    "        return text\n",
    "    else:\n",
    "        print(f\"Could not find main content in {url}\")\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "investopedia_urls = [\n",
    "    \"https://www.investopedia.com/terms/p/price-earningsratio.asp\",\n",
    "    \"https://www.investopedia.com/terms/t/trailingpe.asp\",\n",
    "    \"https://www.investopedia.com/terms/f/forwardpe.asp\",\n",
    "    \"https://www.investopedia.com/terms/p/pegratio.asp\",\n",
    "    \"https://www.investopedia.com/terms/p/price-to-bookratio.asp\",\n",
    "    \"https://www.investopedia.com/terms/e/eps.asp\",\n",
    "    \"https://www.investopedia.com/terms/b/bookvalue.asp\",\n",
    "    \"https://www.investopedia.com/terms/f/freecashflow.asp\",\n",
    "    \"https://www.investopedia.com/terms/e/ebitda.asp\",\n",
    "    \"https://www.investopedia.com/terms/e/enterprisevalue.asp\",\n",
    "    \"https://www.investopedia.com/terms/m/marketcapitalization.asp\",\n",
    "    \"https://www.investopedia.com/terms/r/returnonequity.asp\",\n",
    "    \"https://www.investopedia.com/terms/r/returnoninvestmentcapital.asp\",\n",
    "    \"https://www.investopedia.com/terms/w/wacc.asp\",\n",
    "    \"https://www.investopedia.com/terms/r/returnonassets.asp\",\n",
    "    \"https://www.investopedia.com/terms/e/ebitda-margin.asp\",\n",
    "    \"https://www.investopedia.com/terms/o/operatingmargin.asp\",\n",
    "    \"https://www.investopedia.com/terms/n/net_margin.asp\",\n",
    "    \"https://www.investopedia.com/terms/g/grossmargin.asp\"\n",
    "]\n",
    "\n",
    "investopedia_articles = {}\n",
    "for url in investopedia_urls:\n",
    "    article_text = fetch_investopedia_article(url)\n",
    "    investopedia_articles[url] = article_text\n",
    "    print(f\"Fetched Investopedia article: {url}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sE2UJF9-Y9Hb",
    "outputId": "d0619d25-e0c9-41bd-b4b8-3624508487aa"
   },
   "outputs": [],
   "source": [
    "!pip install wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uy7eJ15WcTj2"
   },
   "outputs": [],
   "source": [
    "import wikipedia\n",
    "\n",
    "pages = [\"Stock market\", \"Bond (finance)\" , \"Mutualfund\", \"Portfolio (finance)\",\n",
    "         \"Exchange-traded fund\", \"Financial statement\", \"Investing\", \"Retirement planning\"]\n",
    "\n",
    "wiki_articles = {}\n",
    "for page in pages:\n",
    "    try:\n",
    "        page_content = wikipedia.page(page).content\n",
    "        wiki_texts[page] = page_content\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching {page}:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ProLcjthcZKe",
    "outputId": "602e185f-f282-46fb-de14-2ad0ed67d93a"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "all_articles = {\n",
    "    \"wikipedia\": wiki_articles,\n",
    "    \"investopedia\": investopedia_articles\n",
    "}\n",
    "\n",
    "with open(\"finance_articles.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(all_articles, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"finance_articles.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mOB2hplKfREo",
    "outputId": "bd2be3c4-79b5-4997-b0a5-e340a7316a59"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "def clean_finance_article(text: str, source: str) -> str:\n",
    "    \"\"\"Clean article text from specific sources with tailored rules\"\"\"\n",
    "    # Common cleaning for all sources\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Replace multiple whitespace\n",
    "    text = re.sub(r'\\[\\d+\\]', '', text)  # Remove citation numbers\n",
    "\n",
    "    # Source-specific cleaning\n",
    "    if source == 'wikipedia':\n",
    "        # Remove edit section links and templates\n",
    "        text = re.sub(r'\\[edit\\]', '', text)\n",
    "        text = re.sub(r'\\{\\{.*?\\}\\}', '', text, flags=re.DOTALL)  # Remove templates\n",
    "\n",
    "        # Remove table of contents section\n",
    "        text = re.sub(r'== Contents ==.*?==', '==', text, flags=re.DOTALL)\n",
    "\n",
    "        # Remove non-content sections\n",
    "        sections_to_remove = [\n",
    "            '== See also ==', '== References ==', '== External links ==',\n",
    "            '== Further reading ==', '== Notes ==', '== Bibliography =='\n",
    "        ]\n",
    "        for section in sections_to_remove:\n",
    "            text = text.split(section)[0]\n",
    "\n",
    "    elif source == 'investopedia':\n",
    "        # Remove disclaimer and ad-related text\n",
    "        text = re.sub(r'(Read our|View) editorial (policies|standards).*?\\.', '', text)\n",
    "        text = re.sub(r'(As of|Updated).*?20\\d{2}', '', text)  # Remove dates\n",
    "        text = re.sub(r'Disclosure:.*?\\.', '', text)\n",
    "\n",
    "        # Remove author/contributor information\n",
    "        text = re.sub(r'By [A-Z][a-z]+ [A-Z][a-z]+', '', text)\n",
    "        text = re.sub(r'Reviewed by .*?\\.', '', text)\n",
    "\n",
    "        # Remove social media prompts\n",
    "        text = re.sub(r'Follow (us|Investopedia) on.*?\\.', '', text)\n",
    "\n",
    "    # Common pattern removal\n",
    "    patterns_to_remove = [\n",
    "        r'This article (was|is) .*?\\.',  # Article metadata\n",
    "        r'Please (read|review) our.*?\\.',  # Policy links\n",
    "        r'Terms of Use apply',\n",
    "        r'Partner Links.*?\\.',\n",
    "        r'Advertisement( - Continue Reading Below)?',\n",
    "        r'Cookie (Policy|Settings)',\n",
    "        r'var\\s+\\w+\\s+=.*?;',  # JavaScript variables\n",
    "        r'<.*?>',  # Remaining HTML tags\n",
    "        r'(\\b[A-Z]+\\b)(?=\\s+[A-Z])'  # Standalone capitalized words (potential ads)\n",
    "    ]\n",
    "\n",
    "    for pattern in patterns_to_remove:\n",
    "        text = re.sub(pattern, '', text)\n",
    "\n",
    "    # Final cleanup\n",
    "    text = text.strip()\n",
    "    text = re.sub(r'\\s+([.,!?])', r'\\1', text)  # Fix punctuation spacing\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Final whitespace cleanup\n",
    "\n",
    "    return text\n",
    "\n",
    "# Load raw data\n",
    "with open(\"finance_articles.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_data = json.load(f)\n",
    "\n",
    "# Clean data\n",
    "cleaned_data = {\"wikipedia\": {}, \"investopedia\": {}}\n",
    "\n",
    "for source in raw_data:\n",
    "    for url, content in raw_data[source].items():\n",
    "        cleaned_content = clean_finance_article(content, source)\n",
    "        cleaned_data[source][url] = cleaned_content\n",
    "\n",
    "# Save cleaned data\n",
    "with open(\"cleaned_finance_articles.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(cleaned_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"Data cleaning complete. Saved as cleaned_finance_articles.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ECs5Z9KMfRyr"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
